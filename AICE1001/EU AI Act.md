The EU AI Act is a piece of legislation published in July 2024, that aims to ensure that artificial intelligence is used ethically and responsibly.
This act splits the uses of AI into four levels of risk
- Unacceptable Risk
	- Systems deemed harmful or manipulative. E.G. social scoring, subliminal manipulation or exploitation. Generally, these things would be illegal without an AI doing them.
- High Risk
	- Systems which either take in highly sensitive data, such as biometric data, or that have high-risk outcomes, such as critical infrastructure management or employment related AI tools.
- Limited Risk
	- Systems with a limited amount of risk. Such systems are generally required to meet higher transparency requirements than normal and make it explicit about the fact that you are interacting not with a human. For example, chatbots fall into this category.
- Minimal Risk
	- All other AI systems. For example, spam filters and video game AIs. These have little to no societal impact and take in no sensitive data.
##### High Risk Requirements
- Must use high quality datasets, minimising bias.
- Must be understandable, such that users can understand how they operate.
- A human must be able to override at any time and remain in control at all times.
- Providers and users must adhere to these rules.
Non-compliance can result in fines of up to â‚¬30 Million or 6% of a company's global annual turnover, whichever is higher.